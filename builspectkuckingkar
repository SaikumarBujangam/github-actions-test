exec_redshift_build()
{
  PYTHON_VAR_LIST=""
  DB_SCHEMA_LIST=""
  CICDVAR_LIST=""
  while test $# -gt 0
  do
    case $1 in
      (--var)
        shift
        parameter_validation "Please provide a DDL file location" "$@" && return 104
        CICDVAR_LIST=$(echo ${CICDVAR_LIST} "--cicdvar ${1}")
        shift;;
      (--artifact-ddl-file)
        shift
        parameter_validation "Please provide a DDL file location" "$@" && return 104
        ARTIFACT_DDL_FILE_LOCATION=${1}
        shift;;
      (--db-name)
        shift
        DB_NAME=${1}
        parameter_validation "Please provide a database name" "$@" && return 105
        shift;;
      (--db-user-name)
        shift
        parameter_validation "Please provide a database name" "$@" && return 106
        DB_USER_NAME=${DATA_PRODUCT_NAME}_${1##${DATA_PRODUCT_NAME}_}
        shift;;
      (--db-cluster-id)
        shift
        parameter_validation "Please provide a database name" "$@" && return 107
        DB_CLUSTER_ID=${1}
        shift;;
      (--db-schema-list)
        shift
        parameter_validation "Please provide a database name" "$@" && return 107
        DB_SCHEMA_LIST="--db-schema-list ${1}"
        shift;;
      (*)
        shift;;
    esac
  done
  run_logger python ${awsdeployrc_root}/src/alight/foundation/app/deploy/redshift.py --base-arg-parser-config-file-location ${awsdeployrc_root}/config --base-arg-parser-config-file-name redshift-build-args.json --artifact-ddl-file ${APP_INSTALL_DIR}/${ARTIFACT_DDL_FILE_LOCATION} --db-name ${DB_NAME} --db-user-name ${DB_USER_NAME} --db-cluster-id ${DB_CLUSTER_ID} ${DB_SCHEMA_LIST} ${CICDVAR_LIST} || true
}

import sys

from alight.foundation.redshift.datapi import DataAPI
from alight.foundation.util.argparsebuilder import GenerateParser
from alight.foundation.util.logging.standardlogger import StandardLogger
from alight.foundation.util.stringutil import StringUtil
from alight.foundation.redshift.utils.replacement import DDLVariableReplacer

if __name__ == "__main__":
  logger = StandardLogger().getDefaultLogger()
  try:
    command_args = GenerateParser(supports_duplicate_parameters=True).build()
    logger.info("Running {} file on cluster: {}. database: {}".format(command_args.artifactDdlFile, command_args.dbClusterId, command_args.dbName))
    redshift_api = DataAPI(db_name=command_args.dbName, db_user_name=command_args.dbUserName, db_cluster_id=command_args.dbClusterId)

    su = StringUtil()
    replacement_params = su.property_list_to_dict(input_list=command_args.cicdVar)
    replacer = DDLVariableReplacer(parameter_dict=replacement_params)
    with open(command_args.artifactDdlFile) as ddl_file:
      ddl_statement=replacer.replace(ddl_file.read())
      for schema_name in command_args.dbSchemaList.split(","):
        execution_statement = []
        if schema_name != "EMBEDDED":
          execution_statement.append("set search_path to {}".format(schema_name))
        execution_statement.append(ddl_statement)
        redshift_api.execute_sql(sql_statement=";\n".join(execution_statement), with_event=command_args.dbWithEvent)
  except Exception as e:
    logger.error(e)
    sys.exit(1)

----RDS Postgres connection detail------------------------
Dev Postgres DC Nexus
adl-com-d1-cdp-dcnexus.cgs723tlzdrk.us-east-1.rds.amazonaws.com
Port â€“ 5432

